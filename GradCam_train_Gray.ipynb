{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10075308940086761895\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7505887651246425420\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4067257079579608019\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5109579776\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1724205501372336380\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,TimeDistributed\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import layers,models\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "import cv2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import heapq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScaleLayer(Layer):\n",
    "\n",
    "    def __init__(self,scale, **kwargs):\n",
    "\n",
    "        self.scale=scale;\n",
    "        \n",
    "        super(ScaleLayer, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ScaleLayer, self).build(input_shape)\n",
    "\n",
    "       \n",
    "    def call(self, inputs):\n",
    "\n",
    "        output=tf.image.resize(inputs,[self.scale,self.scale],method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "        output = tf.keras.backend.concatenate((output, output,output),axis=-1) \n",
    "\n",
    "\n",
    "        print(output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "       \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],self.scale,self.scale,3)\n",
    "\n",
    "\n",
    "\n",
    "def vgg16_head(img_input):\n",
    "\n",
    "    pooling = 'No'\n",
    "\n",
    "    include_top = False;\n",
    "\n",
    "\n",
    "\n",
    "    x = TimeDistributed(ScaleLayer(224))(img_input)\n",
    "\n",
    "    x = TimeDistributed(layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = TimeDistributed(layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = TimeDistributed(layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "        elif pooling =='No':\n",
    "            x = x;\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        \n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "\n",
    "        self.input_shape_r = input_shape;\n",
    "        print('self.input_shape_r')\n",
    "        print(self.input_shape_r)\n",
    "\n",
    "        L_size = 256;\n",
    "\n",
    "        self.w = self.add_weight(name='w', \n",
    "                              shape=[L_size,1],\n",
    "                              initializer='uniform',\n",
    "                              trainable=True)\n",
    "        self.V = self.add_weight(name='V', \n",
    "                      shape=[input_shape[2],L_size],\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "\n",
    "        self.U = self.add_weight(name='U', \n",
    "                      shape=[input_shape[2],L_size],\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "\n",
    "        \n",
    "\n",
    "        self.bias_w = self.add_weight(shape=[1,1],\n",
    "                              initializer='uniform',\n",
    "                              name='bias_w')\n",
    "        self.bias_V = self.add_weight(shape=[1,L_size],\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_V')\n",
    "        self.bias_U = self.add_weight(shape=[1,L_size],\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_U')\n",
    "        \n",
    "\n",
    "  \n",
    "       \n",
    "    def call(self, inputs):\n",
    "\n",
    "\n",
    "        inputs_r = K.expand_dims(inputs,axis=-2)\n",
    "\n",
    "\n",
    "        print('inputs')\n",
    "        print(inputs_r.shape)\n",
    "\n",
    "\n",
    "        dot_products_V = K.dot(inputs_r,self.V)\n",
    "        dot_products_U = K.dot(inputs_r,self.U)\n",
    "\n",
    "        dot_products_V += self.bias_V;\n",
    "        dot_products_U += self.bias_U;\n",
    "\n",
    "\n",
    "        print('dot product')\n",
    "        print(dot_products_V.shape)\n",
    "\n",
    "        tanh_V = K.tanh(dot_products_V);\n",
    "        sigmoid_U = K.sigmoid(dot_products_U);\n",
    "\n",
    "        print('tanh')\n",
    "        print(tanh_V.shape)\n",
    "\n",
    "        comb_UV = tanh_V*sigmoid_U;\n",
    "\n",
    "        print('combUV')\n",
    "        print(comb_UV.shape)\n",
    "\n",
    "        attention_weights = K.dot(comb_UV,self.w);\n",
    "\n",
    "        attention_weights +=self.bias_w;\n",
    "\n",
    "        attention_weights = K.exp(attention_weights);\n",
    "\n",
    "\n",
    "        print('attention_weights')\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "\n",
    "        attention_weights /= K.cast(K.sum(attention_weights,\n",
    "                                  axis=1,\n",
    "                                  keepdims=True) + K.epsilon(),\n",
    "                            K.floatx());\n",
    "        print('attention_weights sum')\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        #attention_weights = K.expand_dims(attention_weights);\n",
    "        attention_weights= K.squeeze(attention_weights,axis = -1);\n",
    "        print('attention_weights last')\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        weighted_output = inputs * attention_weights;\n",
    "\n",
    "        self.Save =  attention_weights;\n",
    "\n",
    "\n",
    "        output = K.sum(weighted_output, axis=1)\n",
    "\n",
    "        print('output')\n",
    "        print(output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],input_shape[2])\n",
    "    \n",
    "    \n",
    "class FCHeadNet:\n",
    "  @staticmethod\n",
    "  def build(baseModel, classes, D):\n",
    "    # initialize the head model that will be placed on top of\n",
    "    # the base, then add a FC layer\n",
    "    headModel = baseModel.output\n",
    "    headModel = TimeDistributed(layers.Flatten(name='flatten'))(headModel)\n",
    "    headModel = TimeDistributed(layers.Dense(D, activation='relu', name='fc1'))(headModel)\n",
    "    headModel = TimeDistributed(layers.Dense(D, activation='relu', name='fc2'))(headModel)\n",
    "    headModel = AttentionLayer(name='attentionlayer')(headModel)\n",
    "    headModel = layers.Dense(classes, activation='softmax', name='predictions')(headModel)\n",
    "    # add a softmax layer\n",
    "    #headModel = layers.Dense(classes, activation=\"softmax\")(headModel)\n",
    "    #headModel = layers.Dense(classes, activation='softmax', name='predictions2')(headModel)\n",
    "\n",
    "    # return the model\n",
    "    return headModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 10, 128, 128, 3)\n",
      "(116,)\n",
      "(87, 10, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "batch_size = 1\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "# the data, split between train and test sets\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "p='/home/peppermint/Data_Sci/Attention_ML/1160_many.h5';\n",
    "\n",
    "db=h5py.File(p);\n",
    "\n",
    "\n",
    "X_stk, y_stk = db['images'],db['labels'];\n",
    "\n",
    "X =np.zeros((116,10,128,128,3))\n",
    "y = np.zeros((116,))\n",
    "\n",
    "for ij in range(116):\n",
    "    X[ij,...] = X_stk[ij*10:(ij+1)*10,...]\n",
    "    y[ij,...] = y_stk[(ij*10+(ij+1)*10)//2]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "total_size = X.shape[0];\n",
    "index_random = np.arange(total_size)\n",
    "i = int(X.shape[0] * 3/4)\n",
    "\n",
    "random.shuffle(index_random)\n",
    "\n",
    "train_index = list(index_random[:i]) ;\n",
    "test_index = list(index_random[i:]) ;\n",
    "train_index.sort()\n",
    "test_index.sort()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = X[train_index],X[test_index],y[train_index],y[test_index];\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "x_train_gray_zero = x_train[...,0]\n",
    "x_train_gray_first = x_train[...,1]\n",
    "x_train_gray_second = x_train[...,2]\n",
    "\n",
    "x_train_gray_zero = x_train_gray_zero[...,None]\n",
    "x_train_gray_first = x_train_gray_first[...,None]\n",
    "x_train_gray_second = x_train_gray_second[...,None]\n",
    "\n",
    "\n",
    "x_test_gray_zero = x_test[...,0]\n",
    "x_test_gray_first = x_test[...,1]\n",
    "x_test_gray_second = x_test[...,2]\n",
    "\n",
    "\n",
    "x_test_gray_zero = x_test_gray_zero[...,None]\n",
    "x_test_gray_first = x_test_gray_first[...,None]\n",
    "x_test_gray_second = x_test_gray_second[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 10, 128, 128, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_gray_zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n",
      "self.input_shape_r\n",
      "(None, 10, 256)\n",
      "inputs\n",
      "(?, 10, 1, 256)\n",
      "dot product\n",
      "(?, 10, 1, 256)\n",
      "tanh\n",
      "(?, 10, 1, 256)\n",
      "combUV\n",
      "(?, 10, 1, 256)\n",
      "attention_weights\n",
      "(?, 10, 1, 1)\n",
      "attention_weights sum\n",
      "(?, 10, 1, 1)\n",
      "attention_weights last\n",
      "(?, 10, 1)\n",
      "output\n",
      "(?, 256)\n",
      "Train on 87 samples, validate on 29 samples\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 0.6564 - accuracy: 0.6628 - val_loss: 0.6078 - val_accuracy: 0.6437\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.5230 - accuracy: 0.7548 - val_loss: 0.5258 - val_accuracy: 0.6897\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.4706 - accuracy: 0.7625 - val_loss: 0.3969 - val_accuracy: 0.8276\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.3842 - accuracy: 0.8046 - val_loss: 0.4638 - val_accuracy: 0.7471\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.3794 - accuracy: 0.8391 - val_loss: 0.3458 - val_accuracy: 0.9425\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.3471 - accuracy: 0.8276 - val_loss: 0.3174 - val_accuracy: 0.8391\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2747 - accuracy: 0.8736 - val_loss: 0.3146 - val_accuracy: 0.8391\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2407 - accuracy: 0.9119 - val_loss: 0.2525 - val_accuracy: 0.9540\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.2185 - accuracy: 0.9349 - val_loss: 0.3199 - val_accuracy: 0.8161\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1944 - accuracy: 0.9157 - val_loss: 0.2307 - val_accuracy: 0.9080\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1439 - accuracy: 0.9655 - val_loss: 0.2560 - val_accuracy: 0.9080\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1135 - accuracy: 0.9885 - val_loss: 0.5043 - val_accuracy: 0.8391\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1813 - accuracy: 0.9272 - val_loss: 0.4055 - val_accuracy: 0.8276\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1020 - accuracy: 0.9693 - val_loss: 0.3041 - val_accuracy: 0.8391\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1437 - accuracy: 0.9387 - val_loss: 0.6843 - val_accuracy: 0.7701\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1053 - accuracy: 0.9693 - val_loss: 0.1915 - val_accuracy: 0.9540\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0722 - accuracy: 0.9693 - val_loss: 0.3720 - val_accuracy: 0.8276\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0670 - accuracy: 0.9770 - val_loss: 0.3600 - val_accuracy: 0.8851\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9310\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9310\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9310\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.1085 - accuracy: 0.9617 - val_loss: 0.2563 - val_accuracy: 0.9080\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9310\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9310\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9080\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9080\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9540\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9310\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9310\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9310\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9310\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9080\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9540\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9310\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9540\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9080\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9310\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9310\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9540\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9310\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9540\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9310\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9540\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9310\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9310\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9310\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9310\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9310\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 9.2404e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9310\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.9785e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7efd3388eb38>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "pooling = 'No'\n",
    "epochs = 50\n",
    "\n",
    "num_classes = 3\n",
    "num_sequence = 10;\n",
    "include_top = False;\n",
    "\n",
    "input_shape =  [num_sequence,img_rows, img_cols, 1];\n",
    "img_input = layers.Input(shape=input_shape)\n",
    "inputs = img_input\n",
    "\n",
    "\n",
    "x = vgg16_head(inputs);\n",
    "\n",
    "# Create model.\n",
    "base_model = models.Model(inputs, x, name='vgg16')\n",
    "\n",
    "weights ='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5';\n",
    "\n",
    "base_model.load_weights(weights)\n",
    "\n",
    "\n",
    "head_model = FCHeadNet.build(base_model, num_classes, 256)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "Dont_Want_to_train_all = True;\n",
    "\n",
    "\n",
    "if (Dont_Want_to_train_all):\n",
    "\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "mcp_save = ModelCheckpoint('weights_lung_gray_zero.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_gray_zero, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_gray_zero, y_test),\n",
    "         callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n",
      "self.input_shape_r\n",
      "(None, 10, 256)\n",
      "inputs\n",
      "(?, 10, 1, 256)\n",
      "dot product\n",
      "(?, 10, 1, 256)\n",
      "tanh\n",
      "(?, 10, 1, 256)\n",
      "combUV\n",
      "(?, 10, 1, 256)\n",
      "attention_weights\n",
      "(?, 10, 1, 1)\n",
      "attention_weights sum\n",
      "(?, 10, 1, 1)\n",
      "attention_weights last\n",
      "(?, 10, 1)\n",
      "output\n",
      "(?, 256)\n",
      "Train on 87 samples, validate on 29 samples\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.7084 - accuracy: 0.6322 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.5664 - accuracy: 0.7050 - val_loss: 0.5093 - val_accuracy: 0.7356\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.5038 - accuracy: 0.7625 - val_loss: 0.4922 - val_accuracy: 0.7356\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.4861 - accuracy: 0.7625 - val_loss: 0.4799 - val_accuracy: 0.7701\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.4074 - accuracy: 0.8084 - val_loss: 0.3999 - val_accuracy: 0.7931\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.3568 - accuracy: 0.8506 - val_loss: 0.4577 - val_accuracy: 0.7816\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.3694 - accuracy: 0.8046 - val_loss: 0.5207 - val_accuracy: 0.7816\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.3259 - accuracy: 0.8697 - val_loss: 0.4659 - val_accuracy: 0.8046\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.3334 - accuracy: 0.8544 - val_loss: 0.3815 - val_accuracy: 0.8161\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.2425 - accuracy: 0.9042 - val_loss: 0.4534 - val_accuracy: 0.7816\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1983 - accuracy: 0.9310 - val_loss: 0.4182 - val_accuracy: 0.8276\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1525 - accuracy: 0.9464 - val_loss: 0.3538 - val_accuracy: 0.8391\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.1747 - accuracy: 0.9464 - val_loss: 0.4900 - val_accuracy: 0.7816\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0934 - accuracy: 0.9693 - val_loss: 0.4391 - val_accuracy: 0.8161\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0932 - accuracy: 0.9655 - val_loss: 0.6385 - val_accuracy: 0.7586\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0624 - accuracy: 0.9962 - val_loss: 0.5430 - val_accuracy: 0.8276\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0672 - accuracy: 0.9732 - val_loss: 0.5186 - val_accuracy: 0.7931\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0386 - accuracy: 0.9923 - val_loss: 0.4411 - val_accuracy: 0.8391\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0580 - accuracy: 0.9732 - val_loss: 0.4165 - val_accuracy: 0.8391\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.8391\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.8391\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.8161\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5405 - val_accuracy: 0.8161\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.8391\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.8391\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8391\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8391\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.8391\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.8161\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.8391\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8391\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.8391\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8161\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8391\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.8391\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.8391\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.8391\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.8391\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8391\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.8391\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.7969e-04 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.8391\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 8.8872e-04 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8391\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 8.3136e-04 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.8391\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 7.5907e-04 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.8391\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 7.2322e-04 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.8391\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 6.5343e-04 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8391\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 6.0826e-04 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.8391\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 5.7345e-04 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.8391\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 5.4235e-04 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.8391\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 4.9741e-04 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.8391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7efd17914438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "pooling = 'No'\n",
    "epochs = 50\n",
    "\n",
    "num_classes = 3\n",
    "num_sequence = 10;\n",
    "include_top = False;\n",
    "\n",
    "input_shape =  [num_sequence,img_rows, img_cols, 1];\n",
    "img_input = layers.Input(shape=input_shape)\n",
    "inputs = img_input\n",
    "\n",
    "\n",
    "x = vgg16_head(inputs);\n",
    "\n",
    "# Create model.\n",
    "base_model = models.Model(inputs, x, name='vgg16')\n",
    "\n",
    "weights ='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5';\n",
    "\n",
    "base_model.load_weights(weights)\n",
    "\n",
    "\n",
    "head_model = FCHeadNet.build(base_model, num_classes, 256)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "Dont_Want_to_train_all = True;\n",
    "\n",
    "\n",
    "if (Dont_Want_to_train_all):\n",
    "\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "mcp_save = ModelCheckpoint('weights_lung_gray_first.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_gray_first, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_gray_first, y_test),\n",
    "         callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n",
      "self.input_shape_r\n",
      "(None, 10, 256)\n",
      "inputs\n",
      "(?, 10, 1, 256)\n",
      "dot product\n",
      "(?, 10, 1, 256)\n",
      "tanh\n",
      "(?, 10, 1, 256)\n",
      "combUV\n",
      "(?, 10, 1, 256)\n",
      "attention_weights\n",
      "(?, 10, 1, 1)\n",
      "attention_weights sum\n",
      "(?, 10, 1, 1)\n",
      "attention_weights last\n",
      "(?, 10, 1)\n",
      "output\n",
      "(?, 256)\n",
      "Train on 87 samples, validate on 29 samples\n",
      "Epoch 1/50\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 0.6787 - accuracy: 0.6245 - val_loss: 0.6161 - val_accuracy: 0.6322\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.6145 - accuracy: 0.6743 - val_loss: 0.5678 - val_accuracy: 0.7011\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.5482 - accuracy: 0.7126 - val_loss: 0.5236 - val_accuracy: 0.7816\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.5385 - accuracy: 0.7165 - val_loss: 0.5786 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.4757 - accuracy: 0.7739 - val_loss: 0.4704 - val_accuracy: 0.7701\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.4129 - accuracy: 0.8276 - val_loss: 0.4924 - val_accuracy: 0.7816\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.4087 - accuracy: 0.8084 - val_loss: 0.4540 - val_accuracy: 0.7931\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.3786 - accuracy: 0.8391 - val_loss: 0.5451 - val_accuracy: 0.7241\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.4092 - accuracy: 0.8008 - val_loss: 0.4961 - val_accuracy: 0.7931\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.3282 - accuracy: 0.8467 - val_loss: 0.4487 - val_accuracy: 0.7931\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.3257 - accuracy: 0.8582 - val_loss: 0.4708 - val_accuracy: 0.7471\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.2647 - accuracy: 0.9119 - val_loss: 0.4127 - val_accuracy: 0.8391\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.2593 - accuracy: 0.8736 - val_loss: 0.4174 - val_accuracy: 0.7931\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.2224 - accuracy: 0.8966 - val_loss: 0.4561 - val_accuracy: 0.8046\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.2099 - accuracy: 0.9080 - val_loss: 0.4048 - val_accuracy: 0.8161\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1517 - accuracy: 0.9540 - val_loss: 0.4382 - val_accuracy: 0.8276\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.1409 - accuracy: 0.9579 - val_loss: 0.4768 - val_accuracy: 0.7471\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1673 - accuracy: 0.9310 - val_loss: 0.4273 - val_accuracy: 0.8736\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.1063 - accuracy: 0.9655 - val_loss: 0.4259 - val_accuracy: 0.7816\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0779 - accuracy: 0.9923 - val_loss: 0.4185 - val_accuracy: 0.7931\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0875 - accuracy: 0.9808 - val_loss: 0.4100 - val_accuracy: 0.7931\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0669 - accuracy: 0.9770 - val_loss: 0.7387 - val_accuracy: 0.7586\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0877 - accuracy: 0.9617 - val_loss: 0.4003 - val_accuracy: 0.8851\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8276\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.8161\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.7816\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.8161\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.8046\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.7931\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.7931\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8276\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8046\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.8046\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.7931\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.8046\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.7931\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.7701\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8046\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5785 - val_accuracy: 0.7931\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.7931\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.7931\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.7931\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.7931\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.7931\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6142 - val_accuracy: 0.8161\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 0.7931\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.8161\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.7931\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.7931\n",
      "Epoch 50/50\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.7931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7efd16a66b38>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "pooling = 'No'\n",
    "epochs = 50\n",
    "\n",
    "num_classes = 3\n",
    "num_sequence = 10;\n",
    "include_top = False;\n",
    "\n",
    "input_shape =  [num_sequence,img_rows, img_cols, 1];\n",
    "img_input = layers.Input(shape=input_shape)\n",
    "inputs = img_input\n",
    "\n",
    "\n",
    "x = vgg16_head(inputs);\n",
    "\n",
    "# Create model.\n",
    "base_model = models.Model(inputs, x, name='vgg16')\n",
    "\n",
    "weights ='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5';\n",
    "\n",
    "base_model.load_weights(weights)\n",
    "\n",
    "\n",
    "head_model = FCHeadNet.build(base_model, num_classes, 256)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "Dont_Want_to_train_all = True;\n",
    "\n",
    "\n",
    "if (Dont_Want_to_train_all):\n",
    "\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "mcp_save = ModelCheckpoint('weights_lung_gray_second.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_gray_second, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_gray_second, y_test),\n",
    "         callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./\"\n",
    "\n",
    "\n",
    "weights_dir = save_dir + \"weights_lung.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_current = weights_dir\n",
    "\n",
    "\n",
    "model.load_weights(model_dir_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-1a15acb6c744>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-1a15acb6c744>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Epoch 13/50\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Epoch 13/50\n",
    " - 9s 99ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.8851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
