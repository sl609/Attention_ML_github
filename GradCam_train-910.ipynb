{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10490271668311462136\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13426475773355298293\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4647271817344184383\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1307049984\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8189069258879463222\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,TimeDistributed\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import layers,models\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "import cv2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import heapq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScaleLayer(Layer):\n",
    "\n",
    "    def __init__(self,scale, **kwargs):\n",
    "\n",
    "        self.scale=scale;\n",
    "        \n",
    "        super(ScaleLayer, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ScaleLayer, self).build(input_shape)\n",
    "\n",
    "       \n",
    "    def call(self, inputs):\n",
    "\n",
    "        output=tf.image.resize(inputs,[self.scale,self.scale],method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "\n",
    "        print(output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "       \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],self.scale,self.scale,3)\n",
    "\n",
    "\n",
    "\n",
    "def vgg16_head(img_input):\n",
    "\n",
    "    pooling = 'No'\n",
    "\n",
    "    include_top = False;\n",
    "\n",
    "\n",
    "\n",
    "    x = TimeDistributed(ScaleLayer(224))(img_input)\n",
    "\n",
    "    x = TimeDistributed(layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = TimeDistributed(layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = TimeDistributed(layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2'))(x)\n",
    "    x = TimeDistributed(layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3'))(x)\n",
    "    x = TimeDistributed(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "        elif pooling =='No':\n",
    "            x = x;\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        \n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "\n",
    "        self.input_shape_r = input_shape;\n",
    "        print('self.input_shape_r')\n",
    "        print(self.input_shape_r)\n",
    "\n",
    "        L_size = 256;\n",
    "\n",
    "        self.w = self.add_weight(name='w', \n",
    "                              shape=[L_size,1],\n",
    "                              initializer='uniform',\n",
    "                              trainable=True)\n",
    "        self.V = self.add_weight(name='V', \n",
    "                      shape=[input_shape[2],L_size],\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "\n",
    "        self.U = self.add_weight(name='U', \n",
    "                      shape=[input_shape[2],L_size],\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "\n",
    "        \n",
    "\n",
    "        self.bias_w = self.add_weight(shape=[1,1],\n",
    "                              initializer='uniform',\n",
    "                              name='bias_w')\n",
    "        self.bias_V = self.add_weight(shape=[1,L_size],\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_V')\n",
    "        self.bias_U = self.add_weight(shape=[1,L_size],\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_U')\n",
    "        \n",
    "\n",
    "  \n",
    "       \n",
    "    def call(self, inputs):\n",
    "\n",
    "\n",
    "        inputs_r = K.expand_dims(inputs,axis=-2)\n",
    "\n",
    "\n",
    "        print('inputs')\n",
    "        print(inputs_r.shape)\n",
    "\n",
    "\n",
    "        dot_products_V = K.dot(inputs_r,self.V)\n",
    "        dot_products_U = K.dot(inputs_r,self.U)\n",
    "\n",
    "        dot_products_V += self.bias_V;\n",
    "        dot_products_U += self.bias_U;\n",
    "\n",
    "\n",
    "        print('dot product')\n",
    "        print(dot_products_V.shape)\n",
    "\n",
    "        tanh_V = K.tanh(dot_products_V);\n",
    "        sigmoid_U = K.sigmoid(dot_products_U);\n",
    "\n",
    "        print('tanh')\n",
    "        print(tanh_V.shape)\n",
    "\n",
    "        comb_UV = tanh_V*sigmoid_U;\n",
    "\n",
    "        print('combUV')\n",
    "        print(comb_UV.shape)\n",
    "\n",
    "        attention_weights = K.dot(comb_UV,self.w);\n",
    "\n",
    "        attention_weights +=self.bias_w;\n",
    "\n",
    "        attention_weights = K.exp(attention_weights);\n",
    "\n",
    "\n",
    "        print('attention_weights')\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "\n",
    "        attention_weights /= K.cast(K.sum(attention_weights,\n",
    "                                  axis=1,\n",
    "                                  keepdims=True) + K.epsilon(),\n",
    "                            K.floatx());\n",
    "        print('attention_weights sum')\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        #attention_weights = K.expand_dims(attention_weights);\n",
    "        attention_weights= K.squeeze(attention_weights,axis = -1);\n",
    "        print('attention_weights last')\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        weighted_output = inputs * attention_weights;\n",
    "\n",
    "        self.Save =  attention_weights;\n",
    "\n",
    "\n",
    "        output = K.sum(weighted_output, axis=1)\n",
    "\n",
    "        print('output')\n",
    "        print(output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],input_shape[2])\n",
    "    \n",
    "    \n",
    "class FCHeadNet:\n",
    "  @staticmethod\n",
    "  def build(baseModel, classes, D):\n",
    "    # initialize the head model that will be placed on top of\n",
    "    # the base, then add a FC layer\n",
    "    headModel = baseModel.output\n",
    "    headModel = TimeDistributed(layers.Flatten(name='flatten'))(headModel)\n",
    "    headModel = TimeDistributed(layers.Dense(D, activation='relu', name='fc1'))(headModel)\n",
    "    headModel = TimeDistributed(layers.Dense(D, activation='relu', name='fc2'))(headModel)\n",
    "    headModel = AttentionLayer(name='attentionlayer')(headModel)\n",
    "    headModel = layers.Dense(classes, activation='softmax', name='predictions')(headModel)\n",
    "    # add a softmax layer\n",
    "    #headModel = layers.Dense(classes, activation=\"softmax\")(headModel)\n",
    "    #headModel = layers.Dense(classes, activation='softmax', name='predictions2')(headModel)\n",
    "\n",
    "    # return the model\n",
    "    return headModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 10, 128, 128, 3)\n",
      "(91,)\n",
      "(68, 10, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "batch_size = 1\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "# the data, split between train and test sets\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "p='/home/peppermint/Data_Sci/Attention_ML/910_many.h5';\n",
    "\n",
    "db=h5py.File(p);\n",
    "\n",
    "\n",
    "X_stk, y_stk = db['images'],db['labels'];\n",
    "\n",
    "X =np.zeros((91,10,128,128,3))\n",
    "y = np.zeros((91,))\n",
    "\n",
    "for ij in range(91):\n",
    "    X[ij,...] = X_stk[ij*10:(ij+1)*10,...]\n",
    "    y[ij,...] = y_stk[(ij*10+(ij+1)*10)//2]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "total_size = X.shape[0];\n",
    "index_random = np.arange(total_size)\n",
    "i = int(X.shape[0] * 3/4)\n",
    "\n",
    "random.shuffle(index_random)\n",
    "\n",
    "train_index = list(index_random[:i]) ;\n",
    "test_index = list(index_random[i:]) ;\n",
    "train_index.sort()\n",
    "test_index.sort()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = X[train_index],X[test_index],y[train_index],y[test_index];\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n",
      "self.input_shape_r\n",
      "(None, 10, 256)\n",
      "inputs\n",
      "(?, 10, 1, 256)\n",
      "dot product\n",
      "(?, 10, 1, 256)\n",
      "tanh\n",
      "(?, 10, 1, 256)\n",
      "combUV\n",
      "(?, 10, 1, 256)\n",
      "attention_weights\n",
      "(?, 10, 1, 1)\n",
      "attention_weights sum\n",
      "(?, 10, 1, 1)\n",
      "attention_weights last\n",
      "(?, 10, 1)\n",
      "output\n",
      "(?, 256)\n",
      "Train on 68 samples, validate on 23 samples\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 7s 107ms/step - loss: 0.9317 - accuracy: 0.4706 - val_loss: 0.8272 - val_accuracy: 0.3043\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 7s 98ms/step - loss: 0.6153 - accuracy: 0.6765 - val_loss: 0.6459 - val_accuracy: 0.6522\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 7s 99ms/step - loss: 0.5798 - accuracy: 0.6471 - val_loss: 0.4984 - val_accuracy: 0.7391\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.4806 - accuracy: 0.7647 - val_loss: 0.4346 - val_accuracy: 0.7391\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.4562 - accuracy: 0.8088 - val_loss: 0.7973 - val_accuracy: 0.4783\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.2982 - accuracy: 0.8676 - val_loss: 0.5425 - val_accuracy: 0.7391\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.2691 - accuracy: 0.9265 - val_loss: 0.3394 - val_accuracy: 0.8261\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.1684 - accuracy: 0.9559 - val_loss: 0.3299 - val_accuracy: 0.8696\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.1421 - accuracy: 0.9412 - val_loss: 0.2107 - val_accuracy: 0.9565\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.1450 - accuracy: 0.9706 - val_loss: 0.3902 - val_accuracy: 0.7826\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.8261\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.7826\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.8696\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.8261\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.8261\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9565\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.8696\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9130\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9565\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.8696\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9130\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.8696\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9130\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9130\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.9130\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9130\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.8696\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.8696\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 7s 109ms/step - loss: 9.7743e-04 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9130\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 7s 109ms/step - loss: 8.8533e-04 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9130\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 7s 108ms/step - loss: 7.8233e-04 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9130\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 7s 110ms/step - loss: 7.1925e-04 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9130\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 7s 110ms/step - loss: 6.5409e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9130\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 8s 110ms/step - loss: 6.0948e-04 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9130\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 7s 110ms/step - loss: 5.5990e-04 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9130\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 7s 110ms/step - loss: 5.0967e-04 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9130\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 7s 110ms/step - loss: 4.7155e-04 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9130\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 7s 105ms/step - loss: 4.3809e-04 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9130\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 7s 99ms/step - loss: 4.1354e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9130\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 3.8971e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9130\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 3.5754e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9130\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 3.3848e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9130\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 3.1609e-04 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9130\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 2.9509e-04 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9130\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 2.7745e-04 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9130\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 2.5944e-04 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9130\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 2.4375e-04 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9130\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 2.2744e-04 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9130\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 2.1540e-04 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9130\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 2.0386e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f0ff7bbe940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "pooling = 'No'\n",
    "epochs = 50\n",
    "\n",
    "num_classes = 2\n",
    "num_sequence = 10;\n",
    "include_top = False;\n",
    "\n",
    "input_shape =  [num_sequence,img_rows, img_cols, 3];\n",
    "img_input = layers.Input(shape=input_shape)\n",
    "inputs = img_input\n",
    "\n",
    "\n",
    "x = vgg16_head(inputs);\n",
    "\n",
    "# Create model.\n",
    "base_model = models.Model(inputs, x, name='vgg16')\n",
    "\n",
    "weights ='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5';\n",
    "\n",
    "base_model.load_weights(weights)\n",
    "\n",
    "\n",
    "head_model = FCHeadNet.build(base_model, num_classes, 256)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "Dont_Want_to_train_all = True;\n",
    "\n",
    "\n",
    "if (Dont_Want_to_train_all):\n",
    "\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "mcp_save = ModelCheckpoint('weights_lung_910.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = getModel()\n",
    "model.summary()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "model.fit(Xtr_more, Ytr_more, batch_size=batch_size, epochs=50, verbose=0, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 19/50\n",
    "7s 101ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_current = weights_dir\n",
    "\n",
    "\n",
    "model.load_weights(model_dir_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
